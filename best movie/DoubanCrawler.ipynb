{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import csv\n",
    "from expanddouban import getHtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "url example:\n",
    "  https://movie.douban.com/tag/#/?sort=S&range=9,10&tags=电影,剧情,美国\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "return a string corresponding to the URL of douban movie lists given category and location.\n",
    "@param category: str\n",
    "@param location: str\n",
    "\"\"\"\n",
    "def getMovieUrl(category, location):\n",
    "    url = 'https://movie.douban.com/tag/#/?sort=S&range=9,10&tags=电影'\n",
    "    return ','.join([url, category, location])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie:\n",
    "    def __init__(self, name, rate, location, category, info_link, cover_link):\n",
    "        self.name = name\n",
    "        self.rate = rate\n",
    "        self.location = location\n",
    "        self.category = category\n",
    "        self.info_link = info_link\n",
    "        self.cover_link = cover_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = getMovieUrl('科幻', '美国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOnePage (url):\n",
    "    html = getHtml(url)\n",
    "    soup = bs(html, 'lxml')\n",
    "    listWpDiv = soup.find(name='div', attrs={'class': 'list-wp'})\n",
    "    if listWpDiv:\n",
    "        listWp = listWpDiv.find_all(name='a', attrs={'class': 'item'})\n",
    "        return [extractOneItem(item) for item in listWp]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def extractOneItem (item):\n",
    "    '''\n",
    "    find title, rate, img\n",
    "    '''\n",
    "    title = item.find(attrs={'class', 'title'}).text\n",
    "    rate = item.find(attrs={'class', 'rate'}).text\n",
    "    img = item.find('img').attrs['src']\n",
    "    return title, rate, img\n",
    "\n",
    "def getMovies (cat, loc):\n",
    "    url = getMovieUrl(cat, loc)\n",
    "    moviesRawData = extractOnePage(url)\n",
    "    return [(mv[0], mv[1], loc, cat, mv[2]) for mv in moviesRawData if mv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = getMovies('剧情', '大陆')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def saveMoviesToCSV (cat, loc):\n",
    "    data = getMovies(cat, lox)\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    [writer.writerow(row) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [\n",
    "    '剧情', '爱情', '喜剧', '科幻',\n",
    "    '动作', '悬疑', '犯罪', '恐怖',\n",
    "    '青春', '励志', '战争', '文艺',\n",
    "    '黑色', '幽默', '传记', '情色',\n",
    "    '暴力','音乐','家庭'\n",
    "]\n",
    "\n",
    "locs = [\n",
    "    '大陆', '美国', '香港', '台湾',\n",
    "    '日本', '韩国', '英国', '法国',\n",
    "    '德国', '意大利', '西班牙',\n",
    "    '印度', '泰国', '俄罗斯', '伊朗',\n",
    "    '加拿大', '澳大利亚', '爱尔兰',\n",
    "    '瑞典', '巴西', '丹麦',\n",
    "]\n",
    "\n",
    "from gevent import monkey, spawn, joinall\n",
    "monkey.patch_socket()\n",
    "def getCatStat (cat):\n",
    "    gs = [spawn(getMovies, cat, loc) for loc in locs]\n",
    "    gs = [g.value for g in joinall(gs)]\n",
    "    return {data[0][2]: len(data) for data in gs if data}\n",
    "\n",
    "def getTop3Loc (cat):\n",
    "    stat = sorted(getCatStat(cat).items(), key=lambda item: item[1])\n",
    "    total = sum([item[1] for item in stat])\n",
    "    statDict = {}\n",
    "    for i in range(3):\n",
    "        item = stat[-1-i]\n",
    "        loc = item[0]\n",
    "        ct = item[1]\n",
    "        pct = round(item[1] / total * 100, 2)\n",
    "        statDict['top'+str(i+1)] = {'loc': loc, 'ct': ct, 'pct': pct}\n",
    "    return {'type': cat, 'stat': statDict} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTop3 ():\n",
    "    return [getTop3Loc(cat) for cat in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': '悬疑', 'stat': {'top1': {'loc': '英国', 'ct': 20, 'pct': 0.36363636363636365}, 'top2': {'loc': '美国', 'ct': 17, 'pct': 0.3090909090909091}, 'top3': {'loc': '日本', 'ct': 7, 'pct': 0.12727272727272726}}}\n",
      "CPU times: user 646 ms, sys: 161 ms, total: 808 ms\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(getTop3Loc(cats[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# allStats = getAllTop3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
